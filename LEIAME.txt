================================= Instruções para criação do conteiner projeto1 ================================================


# Abra o terminal ou prompt de comando e navegue até a pasta onde você colocou os arquivos do projeto1 (não use espaço ou acento em nome de pasta)

# Execute o comando abaixo para criar a imagem Docker no mesmo diretorio onde está o Dockerfile
docker build -t dsa-terraform-image:projeto1 .


# Execute o comando abaixo para criar o container Docker no Linux ou wsl 2
docker run -dit --name dsa-projeto1 -v ./IaC:/iac dsa-terraform-image:projeto1 /bin/bash


[NOTA: No Windows você deve substituir ./IaC pelo caminho completo da pasta, por exemplo: C:\DSA\Cap08\IaC]


# Verifique as versões do Terraform e do AWS CLI com os comandos abaixo no container docker dsa-projeto1

terraform version
aws --version

====================================================== Instruções para o Projeto1 =======================================================

# Projeto 1 - Provisionando Infraestrutura de Processamento de Dados com AWS EMR e Apache Flink

# Crie um bucket no S3 para os dados chamado dsa-p1-<account-id> e configure no arquivo emr.tf

# Crie outro bucket no S3 para os arquivos de log chamado dsa-projeto1-<account-id> e configure no arquivo emr.tf

# Inicializa o Terraform
terraform init

Ao executar o comando anterior, ocorre um error de imagem (dubious ownership). Esse error significa que O Git (dentro do contêiner) percebeu 
que a pasta onde ele está tentando gravar pertence a um usuário diferente do usuário que está rodando o comando. Isso é super comum ao usar Docker 
com volumes montados no Windows/WSL (-v ./IaC:/iac). O Windows é o "dono" do arquivo, mas o Linux do contêiner é o "usuário". Para solucionar este
error, precisei dizer ao Git para "confiar" nessa pasta. Executei este comando dentro do meu terminal (no contêiner ou onde está rodando o Terraform):

git config --global --add safe.directory '*'


# Cria o Plan e salva em disco
terraform plan -var-file config.tfvars -out terraform.tfplan

# Executa o apply com o arquivo de variáveis (com auto-approve)
terraform apply -auto-approve -var-file config.tfvars

# Executa o apply com o arquivo de variáveis (sem auto-approve)
terraform apply -var-file config.tfvars

# Conexão via SSH ao master do cluster
# No container Docker navegue até a pasta onde estão as chaves criadas no deploy do cluster

# Ajusta o privilégio da chave privada
chmod 400 deployer

# Conecta via SSH (coloque abaixo o endereço do seu cluster)
ssh -i deployer hadoop@ec2-3-14-29-59.us-east-2.compute.amazonaws.com

# Crie uma pasta como input no HDFS
hdfs dfs -mkdir /user/root/input

# Copie o arquivo dados.txt do bucket S3 para o sistema de arquivos distribuidos hadoop
hdfs dfs -cp s3://dsa-p1-jobs-124645972365/job/dados.txt /user/root/input

---------------------------- Ignorar -------------------------------------
# Copie o arquivo de dados para o servidor como mostrado nas aulas
# Copie o arquivo para o HDFS
hdfs dfs -put dados.txt /user/root/input
--------------------------------------------------------------------------

# Vamos contar o número de ocorrências de cada palavra no arquivo usando Apache Flink
flink run -m yarn-cluster /usr/lib/flink/examples/streaming/WordCount.jar --input hdfs:///user/root/input/dados.txt --output hdfs:///user/root/saida/

# Copie o arquivo do HDFS para o sistema de arquivos local (conteiner docker)
hdfs dfs -get nome-arquivo-no-HDFS

# Os comandos abaixo devem ser executados no container Docker (máquina cliente)
# Coloque o ID do seu cluster EMR

aws emr add-steps --cluster-id j-14RNI6Q1U71E3 \
--steps Type=CUSTOM_JAR,Name=Job1_P1,Jar=command-runner.jar,\
Args="flink","run","-m","yarn-cluster",\
"/usr/lib/flink/examples/streaming/WordCount.jar",\
"--input","hdfs:///user/root/input/dados.txt","--output","hdfs:///user/root/saidajob1/" \
--region us-east-2

aws emr add-steps --cluster-id j-14RNI6Q1U71E3 \
--steps Type=CUSTOM_JAR,Name=Job2_P1,Jar=command-runner.jar,\
Args="flink","run","-m","yarn-cluster",\
"/usr/lib/flink/examples/streaming/WordCount.jar",\
"--input","s3://dsa-p1-jobs-124645972365/job/dados.txt","--output","s3://dsa-p1-jobs-124645972365/" \
--region us-east-2

# Cria o Plan para o destroy e salva em disco
terraform plan -destroy -var-file config.tfvars -out terraform.tfplan

# Executa o destroy
terraform apply terraform.tfplan